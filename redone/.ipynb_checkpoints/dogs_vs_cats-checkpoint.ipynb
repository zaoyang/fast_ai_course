{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs\n"
     ]
    }
   ],
   "source": [
    "%cd ~/nbs/\n",
    "%pwd\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs\n",
      "/home/ubuntu/nbs/data/dogscats\n"
     ]
    }
   ],
   "source": [
    "import os, sys \n",
    "currentDir = os.getcwd() \n",
    "HOME_DIR = currentDir\n",
    "DATA_DIR = currentDir + '/data/dogscats'\n",
    "print HOME_DIR\n",
    "print DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), \"orig\" ))\n",
    "\n",
    "from utils import * \n",
    "from vgg16 import Vgg16 \n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/dogscats\n",
      "mkdir: cannot create directory ‘results’: File exists\n",
      "/home/ubuntu/nbs/data/dogscats/train\n",
      "/home/ubuntu/nbs/data/dogscats/valid\n"
     ]
    }
   ],
   "source": [
    "# Create directories\n",
    "%cd $DATA_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown\n",
    "%cd $DATA_DIR/train\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2000): os.rename(shuf[i], DATA_DIR+'/valid/' + shuf[i])\n",
    "from shutil import copyfile\n",
    "\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200): copyfile(shuf[i], DATA_DIR+'/sample/train/' + shuf[i])\n",
    "\n",
    "%cd $DATA_DIR/valid\n",
    "\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(50): copyfile(shuf[i], DATA_DIR+'/sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide cats and dogs to different directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/dogscats/sample/train\n",
      "mkdir: cannot create directory ‘cats’: File exists\n",
      "mkdir: cannot create directory ‘dogs’: File exists\n",
      "mv: cannot stat 'cat.*.jpg': No such file or directory\n",
      "mv: cannot stat 'dog.*.jpg': No such file or directory\n",
      "/home/ubuntu/nbs/data/dogscats/sample/valid\n",
      "mkdir: cannot create directory ‘cats’: File exists\n",
      "mkdir: cannot create directory ‘dogs’: File exists\n",
      "mv: cannot stat 'cat.*.jpg': No such file or directory\n",
      "mv: cannot stat 'dog.*.jpg': No such file or directory\n",
      "/home/ubuntu/nbs/data/dogscats/valid\n",
      "mkdir: cannot create directory ‘cats’: File exists\n",
      "mkdir: cannot create directory ‘dogs’: File exists\n",
      "mv: cannot stat 'cat.*.jpg': No such file or directory\n",
      "mv: cannot stat 'dog.*.jpg': No such file or directory\n",
      "/home/ubuntu/nbs/data/dogscats/train\n",
      "mkdir: cannot create directory ‘cats’: File exists\n",
      "mkdir: cannot create directory ‘dogs’: File exists\n",
      "mv: cannot stat 'cat.*.jpg': No such file or directory\n",
      "mv: cannot stat 'dog.*.jpg': No such file or directory\n",
      "/home/ubuntu/nbs/data/dogscats/test\n"
     ]
    }
   ],
   "source": [
    "# Divide cat/dog images into separate directories\n",
    "\n",
    "%cd $DATA_DIR/sample/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_DIR/sample/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_DIR/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_DIR/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "\n",
    "#Create single 'unknown' class for test set\n",
    "%cd $DATA_DIR/test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create validation and test sets from original set (there are a bunch of moving images that you can use \n",
    "2. Download weights \n",
    "3. Finetune weights \n",
    "4. Generate predictions \n",
    "5. Validate predictions \n",
    "6. Submit everything to Kaggle \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/dogscats\n",
      "/home/ubuntu/nbs/data/dogscats/sample/\n",
      "/home/ubuntu/nbs/data/dogscats/test/\n",
      "/home/ubuntu/nbs/data/dogscats/results/\n",
      "/home/ubuntu/nbs/data/dogscats/sample//train/\n",
      "/home/ubuntu/nbs/data/dogscats/sample//valid/\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_DIR + '/sample/' #'/sample/'\n",
    "test_path = DATA_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'\n",
    "\n",
    "vgg = Vgg16() \n",
    "print path\n",
    "print test_path\n",
    "print results_path\n",
    "print train_path \n",
    "print valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64 \n",
    "numEpochs=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n",
      "['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "batches=vgg.get_batches(train_path, batch_size=batch_size)\n",
    "valid_batches = vgg.get_batches(valid_path, batch_size=batch_size)\n",
    "vgg.finetune(batches)\n",
    "print vgg.classes\n",
    "\n",
    "# set the learning rate \n",
    "# the optimizer is what runs gradient descent and \n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "lastEpochFileName = None \n",
    "for epoch in range(numEpochs): \n",
    "    print \"Running epoch: %d\" % epoch \n",
    "    vgg.fit(batches, valid_batches, nb_epoch=1)\n",
    "    lastEpochFileName = 'ft%d.h5' % epoch \n",
    "    vgg.model.save_weights(results_path + lastEpochFileName)\n",
    "\n",
    "print \"Complete %s fit operations \" % epoch \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have the validation and trainin set and training for 3 epochs, then you'll have to then now test it '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the prediction \n",
    "# use gen.flow_from_directory using shuffle=False, batch_size=8, class_mode=None\n",
    "# \n",
    "batches, pred = vgg.test(test_path, batch_size=batch_size*2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print batches.filenames[:5]\n",
    "print batches.classes[:5]\n",
    "print pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "a = Image(filename=test_path + batches.filenames[0]) \n",
    "b = Image(filename=test_path + batches.filenames[1])\n",
    "c = Image(filename=test_path + batches.filenames[2]) \n",
    "d = Image(filename=test_path + batches.filenames[3]) \n",
    "e = Image(filename=test_path + batches.filenames[4]) \n",
    "display(a, b, c, d, e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_array(results_path + \"test_pred\", pred)\n",
    "save_array(results_path + \"filenames.dat\", batches.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do the fit/predic cycle for vaidation set. Get \n",
    "2. Get predictions in log prob form \n",
    "3. Convert to rounded up to classes \n",
    "4. Compare against classes already in validation directory \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load using training set models \n",
    "vgg.model.load_weights(results_path + lastEpochFileName) \n",
    "val_batches, val_predictions = vgg.test(valid_path, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames\n",
    "expected_classes =  val_batches.classes # dogs and cats labels with 0 and 1. This is taken from the directory directly \n",
    "\n",
    "print val_predictions # these predictions are low decimals \n",
    "\n",
    "sliced_predictions = val_predictions[:,0] # sliced with only column 0 \n",
    "rounded_predictions = np.round(1-our_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image \n",
    "\n",
    "def plots_idx(idx, titles=None): \n",
    "    plots([image.load_img(valid_path+ filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "num_imgs_to_view = 4 \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view images at random \n",
    "correct = np.where(our_labels==expected_classes)[0] # return array correct [ 0  1  2  3  4 5] ex. [0] necessary \n",
    "print \"Found %d correct labels: \" % len(correct)\n",
    "idx = permutation(correct)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_classes)[0]\n",
    "print \"Found %d incorrect labels: \" % len(incorrect)\n",
    "idx = permutation(incorrect)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels == 1) & (our_labels == expected_labels))[0]\n",
    "print \"Found %d correct cats: \" % len(correct_cats)\n",
    "idx = permutation(correct_cats)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels == 0) & (our_labels == expected_labels))[0]\n",
    "print \"Found % correct dogs: \" % len(correct_dogs)\n",
    "idx = permutation(correct_dogs)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels == 0) & (our_labels != expected_labels))[0]\n",
    "print \"Found % inspections  \" % len(incorrect_cats)\n",
    "idx = permutations(incorrect_cats)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels == 1) & (our_labels != expected_labels))[0]\n",
    "print \"Found % incorrect dogs \" % len(incorrect_dogs)\n",
    "idx = permutations(incorrect_dogs)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "uncertain_labels = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(uncertain_labels[:num_imgs_to_view], our_predictions[most_uncertain])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate predictions with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submit items to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load back the files into arrays (prediction and the filenames) \n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
