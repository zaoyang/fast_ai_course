{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs\n"
     ]
    }
   ],
   "source": [
    "%cd ~/nbs/\n",
    "%pwd\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs\n",
      "/home/ubuntu/nbs/data/dogscats\n"
     ]
    }
   ],
   "source": [
    "import os, sys \n",
    "currentDir = os.getcwd() \n",
    "HOME_DIR = currentDir\n",
    "DATA_DIR = currentDir + '/data/dogscats'\n",
    "print HOME_DIR\n",
    "print DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), \"orig\" ))\n",
    "\n",
    "from utils import * \n",
    "from vgg16 import Vgg16 \n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create validation and test sets from original set (there are a bunch of moving images that you can use \n",
    "2. Download weights \n",
    "3. Finetune weights \n",
    "4. Generate predictions \n",
    "5. Validate predictions \n",
    "6. Submit everything to Kaggle \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/data/dogscats\n",
      "/home/ubuntu/nbs/data/dogscats/sample/\n",
      "/home/ubuntu/nbs/data/dogscats/test/\n",
      "/home/ubuntu/nbs/data/dogscats/results/\n",
      "/home/ubuntu/nbs/data/dogscats/sample//train/\n",
      "/home/ubuntu/nbs/data/dogscats/sample//valid/\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_DIR + '/sample/' #'/sample/'\n",
    "test_path = DATA_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'\n",
    "\n",
    "vgg = Vgg16() \n",
    "print path\n",
    "print test_path\n",
    "print results_path\n",
    "print train_path \n",
    "print valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64 \n",
    "numEpochs=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "batches=vgg.get_batches(train_path, batch_size=batch_size)\n",
    "valid_batches = vgg.get_batches(valid_path, batch_size=batch_size)\n",
    "vgg.finetune(batches)\n",
    "print vgg.classes\n",
    "\n",
    "# set the learning rate \n",
    "# the optimizer is what runs gradient descent and \n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 14s - loss: 2.5323 - acc: 0.3125 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 13s - loss: 2.8016e-05 - acc: 1.0000 - val_loss: 2.7357e-04 - val_acc: 1.0000\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 14s - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 2.1573e-05 - val_acc: 1.0000\n",
      "Complete 2 fit operations \n"
     ]
    }
   ],
   "source": [
    "lastEpochFileName = None \n",
    "for epoch in range(numEpochs): \n",
    "    print \"Running epoch: %d\" % epoch \n",
    "    vgg.fit(batches, valid_batches, nb_epoch=1)\n",
    "    lastEpochFileName = 'ft%d.h5' % epoch \n",
    "    vgg.model.save_weights(results_path + lastEpochFileName)\n",
    "\n",
    "print \"Complete %s fit operations \" % epoch \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have the validation and trainin set and training for 3 epochs, then you'll have to then now test it '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# do the prediction \n",
    "# use gen.flow_from_directory using shuffle=False, batch_size=8, class_mode=None\n",
    "# \n",
    "batches, pred = vgg.test(test_path, batch_size=batch_size*2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print batches.filenames[:5]\n",
    "print batches.classes[:5]\n",
    "print pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "a = Image(filename=test_path + batches.filenames[0]) \n",
    "b = Image(filename=test_path + batches.filenames[1])\n",
    "c = Image(filename=test_path + batches.filenames[2]) \n",
    "d = Image(filename=test_path + batches.filenames[3]) \n",
    "e = Image(filename=test_path + batches.filenames[4]) \n",
    "display(a, b, c, d, e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_array(results_path + \"test_pred\", pred)\n",
    "save_array(results_path + \"filenames.dat\", batches.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do the fit/predic cycle for vaidation set. Get \n",
    "2. Get predictions in log prob form \n",
    "3. Convert to rounded up to classes \n",
    "4. Compare against classes already in validation directory \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load using training set models \n",
    "vgg.model.load_weights(results_path + lastEpochFileName) \n",
    "val_batches, val_predictions = vgg.test(valid_path, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames\n",
    "expected_classes =  val_batches.classes # dogs and cats labels with 0 and 1. This is taken from the directory directly \n",
    "\n",
    "print val_predictions # these predictions are low decimals \n",
    "\n",
    "sliced_predictions = val_predictions[:,0] # sliced with only column 0 \n",
    "rounded_predictions = np.round(1-our_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image \n",
    "\n",
    "def plots_idx(idx, titles=None): \n",
    "    plots([image.load_img(valid_path+ filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "num_imgs_to_view = 4 \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view images at random \n",
    "correct = np.where(our_labels==expected_classes)[0] # return array correct [ 0  1  2  3  4 5] ex. [0] necessary \n",
    "print \"Found %d correct labels: \" % len(correct)\n",
    "idx = permutation(correct)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_classes)[0]\n",
    "print \"Found %d incorrect labels: \" % len(incorrect)\n",
    "idx = permutation(incorrect)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels == 1) & (our_labels == expected_labels))[0]\n",
    "print \"Found %d correct cats: \" % len(correct_cats)\n",
    "idx = permutation(correct_cats)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels == 0) & (our_labels == expected_labels))[0]\n",
    "print \"Found % correct dogs: \" % len(correct_dogs)\n",
    "idx = permutation(correct_dogs)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels == 0) & (our_labels != expected_labels))[0]\n",
    "print \"Found % inspections  \" % len(incorrect_cats)\n",
    "idx = permutations(incorrect_cats)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels == 1) & (our_labels != expected_labels))[0]\n",
    "print \"Found % incorrect dogs \" % len(incorrect_dogs)\n",
    "idx = permutations(incorrect_dogs)[:num_imgs_to_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "uncertain_labels = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(uncertain_labels[:num_imgs_to_view], our_predictions[most_uncertain])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate predictions with Cofusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
